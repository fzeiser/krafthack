{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/')\n",
    "TEST_SPLIT_SIZE = .2\n",
    "SEED = 125501\n",
    "N_EPOCHS=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1874087, 22)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(DATA_PATH / 'input_dataset-2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = df.columns.tolist()[:7]\n",
    "LABEL_COLUMN = ['Bolt_1_Tensile']\n",
    "\n",
    "FEATURE_COLUMNS = FEATURE_COLUMNS + LABEL_COLUMN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 125501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125501"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = df[FEATURE_COLUMNS].copy()\n",
    "\n",
    "feature_df.dropna(inplace=True)\n",
    "\n",
    "mode_le = LabelEncoder()\n",
    "\n",
    "feature_df['mode'] = mode_le.fit_transform(feature_df['mode'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(feature_df, test_size=TEST_SPLIT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "scaler.fit(train_df)\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    scaler.transform(train_df), index=train_df.index, columns=train_df.columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400000, 8)\n",
      "(350000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(input_data: pd.DataFrame, target_column, sequence_length=60):\n",
    "    sequences = []\n",
    "    data_size = len(input_data)\n",
    "\n",
    "    for i in tqdm(range(data_size - sequence_length)):\n",
    "        sequence = input_data[i: i + sequence_length]\n",
    "        label_position = i + sequence_length\n",
    "        label = input_data.iloc[label_position][target_column]\n",
    "\n",
    "        sequences.append((sequence, label))\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65828af4aedc41e69df078d84fcad256",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1399940 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sequences = create_sequences(train_df, LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d9dacddf6a4c71805a0a93f016961c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/349940 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sequences = create_sequences(test_df, LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KrafthackDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, label = self.sequences[idx]\n",
    "\n",
    "        return dict(sequence=torch.Tensor(sequence.to_numpy()), label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KrafthackDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_sequences, test_sequences, batch_size=8):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self):\n",
    "        self.train_dataset = KrafthackDataset(self.train_sequences)\n",
    "        self.test_dataset = KrafthackDataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = KrafthackDataModule(\n",
    "    train_sequences=train_sequences, test_sequences=test_sequences, batch_size=128\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensilePredictionModel(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=128, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_hidden,\n",
    "            batch_first=True,\n",
    "            num_layers=n_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "\n",
    "        logits = hidden[-1]\n",
    "\n",
    "        return self.regressor(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensilePredictor(pl.LightningModule):\n",
    "    def __init__(self, n_features: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = TensilePredictionModel(n_features)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, _ = self(sequences, labels)\n",
    "        self.log(\"training_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, _ = self(sequences, labels)\n",
    "        self.log(\"validation_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, _ = self(sequences, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TensilePredictor(n_features = train_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"tensile-pred\")\n",
    "\n",
    "progress_callback = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    enable_checkpointing=checkpoint_callback,\n",
    "    callbacks=[early_stopping_callback, progress_callback],\n",
    "    max_epochs=N_EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b8447743059096f57ea22d046b7813d657cfcf124ac271c0edc0370df92b8f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
