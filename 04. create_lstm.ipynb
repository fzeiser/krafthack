{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn, optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/')\n",
    "TEST_SPLIT_SIZE = .2\n",
    "SEED = 125501\n",
    "N_EPOCHS=10\n",
    "FRAC=.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(DATA_PATH / 'input_dataset-2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLUMNS = df.columns.tolist()[:7]\n",
    "LABEL_COLUMN = 'Bolt_1_Tensile'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 125501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125501"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df.sample(frac=FRAC, random_state=SEED)[FEATURE_COLUMNS].copy()\n",
    "\n",
    "features_df.dropna(inplace=True)\n",
    "\n",
    "features_df['label'] = df[LABEL_COLUMN]\n",
    "\n",
    "mode_le = LabelEncoder()\n",
    "\n",
    "features_df['mode'] = mode_le.fit_transform(features_df['mode'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(features_df, test_size=TEST_SPLIT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "scaler.fit(train_df)\n",
    "\n",
    "train_df = pd.DataFrame(\n",
    "    scaler.transform(train_df), index=train_df.index, columns=train_df.columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140016, 8)\n",
      "(35005, 8)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9820dbde46ea4f19a5c4ef830a2dcead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sequences(input_data: pd.DataFrame, feature_columns, target_column, sequence_length=60):\n",
    "    sequences = []\n",
    "    data_size = len(input_data)\n",
    "\n",
    "    sequence = input_data[feature_columns][:sequence_length].to_numpy().tolist()\n",
    "    all_labels = input_data[target_column].to_list()\n",
    "\n",
    "    for i in tqdm(range(1, data_size - sequence_length)):\n",
    "        row_dict = input_data.iloc[i].to_dict()\n",
    "        feats = [row_dict[x] for x in feature_columns]\n",
    "        \n",
    "        sequence.pop()\n",
    "        sequence.append(feats)\n",
    "\n",
    "        label_position = i + sequence_length\n",
    "        label = all_labels[label_position]\n",
    "\n",
    "        sequences.append((sequence, label))\n",
    "\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f335ef317b45bd8a35978e7062a37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/139955 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_sequences = create_sequences(train_df, FEATURE_COLUMNS, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ab6957365b417bb953654178aabc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_sequences = create_sequences(test_df, FEATURE_COLUMNS, 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KrafthackDataset(Dataset):\n",
    "    def __init__(self, sequences):\n",
    "        self.sequences = sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sequence, label = self.sequences[idx]\n",
    "\n",
    "        return dict(\n",
    "            sequence=torch.Tensor(sequence.to_numpy()), label=torch.tensor(label)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KrafthackDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_sequences, test_sequences, batch_size=256):\n",
    "        super().__init__()\n",
    "        self.train_sequences = train_sequences\n",
    "        self.test_sequences = test_sequences\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self):\n",
    "        self.train_dataset = KrafthackDataset(self.train_sequences)\n",
    "        self.test_dataset = KrafthackDataset(self.test_sequences)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=1, shuffle=False, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = KrafthackDataModule(\n",
    "    train_sequences=train_sequences, test_sequences=test_sequences, batch_size=128\n",
    ")\n",
    "\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensilePredictionModel(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden=128, n_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=n_features,\n",
    "            hidden_size=n_hidden,\n",
    "            batch_first=True,\n",
    "            num_layers=n_layers,\n",
    "            dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.lstm.flatten_parameters()\n",
    "\n",
    "        _, (hidden, _) = self.lstm(x)\n",
    "\n",
    "        logits = hidden[-1]\n",
    "\n",
    "        return self.regressor(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensilePredictor(pl.LightningModule):\n",
    "    def __init__(self, n_features: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = TensilePredictionModel(n_features)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        output = self.model(x)\n",
    "        loss = 0\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.criterion(output, labels.unsqueeze(dim=1))\n",
    "\n",
    "        return loss, output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, _ = self(sequences, labels)\n",
    "        self.log(\"training_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, _ = self(sequences, labels)\n",
    "        self.log(\"validation_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        sequences = batch[\"sequence\"]\n",
    "        labels = batch[\"label\"]\n",
    "        loss, _ = self(sequences, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TensilePredictor(n_features = train_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints\",\n",
    "    filename=\"best-checkpoint\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"tensile-pred\")\n",
    "\n",
    "progress_callback = TQDMProgressBar(refresh_rate=10)\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=2\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    enable_checkpointing=checkpoint_callback,\n",
    "    callbacks=[early_stopping_callback, progress_callback],\n",
    "    max_epochs=N_EPOCHS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoandinkov/Desktop/hackathon/code/.venv/lib/python3.9/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
      "  rank_zero_deprecation(\n",
      "Missing logger folder: lightning_logs/tensile-pred\n",
      "\n",
      "  | Name      | Type                   | Params\n",
      "-----------------------------------------------------\n",
      "0 | model     | TensilePredictionModel | 202 K \n",
      "1 | criterion | MSELoss                | 0     \n",
      "-----------------------------------------------------\n",
      "202 K     Trainable params\n",
      "0         Non-trainable params\n",
      "202 K     Total params\n",
      "0.812     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoandinkov/Desktop/hackathon/code/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/homebrew/Cellar/python@3.9/3.9.10/Frameworks/Python.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'KrafthackDataset' on <module '__main__' (built-in)>\n",
      "/Users/yoandinkov/Desktop/hackathon/code/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/yoandinkov/Desktop/hackathon/code/04. create_lstm.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yoandinkov/Desktop/hackathon/code/04.%20create_lstm.ipynb#ch0000036?line=0'>1</a>\u001b[0m data_module\u001b[39m.\u001b[39;49mtrain_dataset[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;32m/Users/yoandinkov/Desktop/hackathon/code/04. create_lstm.ipynb Cell 16'\u001b[0m in \u001b[0;36mKrafthackDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yoandinkov/Desktop/hackathon/code/04.%20create_lstm.ipynb#ch0000008?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yoandinkov/Desktop/hackathon/code/04.%20create_lstm.ipynb#ch0000008?line=8'>9</a>\u001b[0m     sequence, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msequences[idx]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yoandinkov/Desktop/hackathon/code/04.%20create_lstm.ipynb#ch0000008?line=10'>11</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mdict\u001b[39m(\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yoandinkov/Desktop/hackathon/code/04.%20create_lstm.ipynb#ch0000008?line=11'>12</a>\u001b[0m         sequence\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mTensor(sequence\u001b[39m.\u001b[39;49mto_numpy()), label\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mtensor(label)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yoandinkov/Desktop/hackathon/code/04.%20create_lstm.ipynb#ch0000008?line=12'>13</a>\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to_numpy'"
     ]
    }
   ],
   "source": [
    "data_module.train_dataset[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b8447743059096f57ea22d046b7813d657cfcf124ac271c0edc0370df92b8f4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
